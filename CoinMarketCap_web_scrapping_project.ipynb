{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a845980",
   "metadata": {},
   "source": [
    "   # Scraping Cryptocurrency Historical Data Snapshot Using python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0320294f",
   "metadata": {},
   "source": [
    ">Firstly going directly into the project lets have a look on Web scrapping!\n",
    "\n",
    "![img](https://i.imgur.com/6whNLgu.jpg)\n",
    "\n",
    "[Web Scraping](https://www.geeksforgeeks.org/what-is-web-scraping-and-how-to-use-it/) is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf7dfd5",
   "metadata": {},
   "source": [
    "[CoinMarketCap](https://coinmarketcap.com/) is the world's most-referenced price-tracking website for cryptoassets in the rapidly growing cryptocurrency space. Its mission is to make crypto discoverable and efficient globally by empowering retail users with unbiased, high quality and accurate information for drawing their own informed conclusions. \n",
    "For example, [Historical Snapshots](https://coinmarketcap.com/historical/) contains the entire data in weekly format of the cryptocurrencies till present date.\n",
    "\n",
    "\n",
    "![Screen Shot](https://i.imgur.com/sQkgxVl.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The page https://coinmarketcap.com/historical/ of cryptocurrencies, started in April 2013. This [page](https://coinmarketcap.com/historical/) provides a list of weekly date's of months and years, That date's contains Web browsing link of cryptocurrencies of last seven day records.\n",
    "\n",
    "\n",
    "In this project, We'll retrieve information from this [page](https://coinmarketcap.com/historical/) and cryptocurrencies [page](https://coinmarketcap.com/historical/20130505/) Which is corresponding to the date's of first page using \"Web scrapping\". We'll use the python libraries [Requests](https://requests.readthedocs.io/en/latest/) and [Beautiful Soup](https://beautiful-soup-4.readthedocs.io/en/latest/) to scrape data from first page. And [Selenium](https://selenium-python.readthedocs.io/) to scrape data corresponding [page](https://coinmarketcap.com/historical/20130505/)\n",
    "\n",
    ">1. Python is one of the most popular languages for web scraping as it has a variety of libraries that are specifically created for Web Scraping.\n",
    ">2. Beautiful soup is another Python library that is highly suitable for Web Scraping, It creates a parse tree that can be used to extract data from HTML on a website.\n",
    ">3. Selenium Webdriver is a tool for testing the front end of an application, it is used to perform browser manipulation in web scraping\n",
    ">4. Pandas is a tool used to read and manipulate the data.\n",
    "\n",
    "\n",
    "After scrapping data from first page, We make an automated format in which we give input as date, month, and year to first page data and then using this input we get a link of that particular 'date' and then scrape that 'link' page and generate a csv of historical data.\n",
    "\n",
    "[CoinMarketCap](https://coinmarketcap.com/) is a [dynamic website](https://www.geeksforgeeks.org/difference-between-static-and-dynamic-web-pages/) or dynamic web page contains information that changes, depending on the viewer, the time of the day, the time zone, the viewer's native language, and other factors.\n",
    "\n",
    "Generally, We use Beautiful Soup for [static](https://www.geeksforgeeks.org/difference-between-static-and-dynamic-web-pages/) and Selenium for [dynamic website](https://www.geeksforgeeks.org/difference-between-static-and-dynamic-web-pages/) to scrape data.\n",
    "\n",
    "But here, We will scratch first [page](https://coinmarketcap.com/historical/) using Beautiful soup, On that page data is distributed in static way.\n",
    "\n",
    "\n",
    "And second [page](https://coinmarketcap.com/historical/20130505/) using Selenium where, data loaded in automated form when you scroll down your page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f942bf52",
   "metadata": {},
   "source": [
    "Here's an outline of the steps we'll follow for first [page](https://coinmarketcap.com/historical/)\n",
    ">1. Download the webpage using `requests`\n",
    ">2. Parse the HTML source code using beautiful soup\n",
    ">3. Compile extracted information into python lists and dictionaries\n",
    ">4. Save the extracted information to a dataframe\n",
    ">5. Get the desire link using input functions for a input data(like date,moonth and year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcd8abd",
   "metadata": {},
   "source": [
    "Here's an outline of the steps we'll follow for second [page](https://coinmarketcap.com/historical/20130505/) .\n",
    ">1. Install and Import the required packages.\n",
    ">2. Create the selenium webdriver object and Load url into driver\n",
    ">3. Compile extracted information into python lists and dictionaries\n",
    ">4. Save the extracted information to a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edc92f9",
   "metadata": {},
   "source": [
    "## Install and Import required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1144a29",
   "metadata": {},
   "source": [
    "### Install Libraries\n",
    "We can use `!pip` to install library in jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbeaeb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests --upgrade --quiet\n",
    "!pip install beautifulsoup4 --upgrade --quiet\n",
    "!pip install selenium --upgrade --quiet\n",
    "!pip install pandas --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e69dbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in c:\\users\\aehtajaz ahmed\\anaconda3\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: requests in c:\\users\\aehtajaz ahmed\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.28.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aehtajaz ahmed\\anaconda3\\lib\\site-packages (from webdriver-manager) (4.64.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\aehtajaz ahmed\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aehtajaz ahmed\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aehtajaz ahmed\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aehtajaz ahmed\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\aehtajaz ahmed\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\aehtajaz ahmed\\anaconda3\\lib\\site-packages (from tqdm->webdriver-manager) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004537a2",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5632eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "# WebDriver class will connect us to a browserâ€™s instance\n",
    "from selenium import webdriver\n",
    "\n",
    "# Keys class lets us emulate the stroke of keyboard keys\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "#Object that manages the starting and stopping of the ChromeDriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "# Use with Chrome\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Set of supported locator strategies.\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# used to manipulate various properties of Chrome driver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "#import time\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd566ad",
   "metadata": {},
   "source": [
    "To download a page, we can use the `get` function from `requests`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a93b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_url = 'https://coinmarketcap.com/historical/'\n",
    "response = requests.get(page_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17417d86",
   "metadata": {},
   "source": [
    "`requests.get` returns a response object containing the data from the web page and some other information.\n",
    "\n",
    "The `.status_code` property can be used to check if the request was successful. A succesful response will have an [HTTP status COde](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status) between 200 and 299."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acd44ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbe713d",
   "metadata": {},
   "source": [
    "The request was successful We can get the contents of the page using `response.text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8722507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_content = response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c84144",
   "metadata": {},
   "source": [
    "Let's check the no. of characters on the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "361269cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133149"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cfe0c4",
   "metadata": {},
   "source": [
    "The page contains over 120,000 characters! Here are the first 500 characters of the page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41b993dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html><html lang=\"en\" dir=\"ltr\"><head><meta charSet=\"utf-8\"/><meta http-equiv=\"x-ua-compatible\" content=\"ie=edge\"/><meta name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no, shrink-to-fit=no\"/><script>(function() {if (false) {window.__renderTime__.csrRender = 1672588904140;return;}window.__renderTime__ = {\"pageInitStart\":1672588904129,\"pageInitEnd\":1672588904138,\"pageRender\":1672588904140};window.__renderTime__.pageLoad = Date.now();})()</scri'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_content[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140bbcb8",
   "metadata": {},
   "source": [
    "What we're looking at above is the [HTML source code](https://developer.mozilla.org/en-US/docs/Web/HTML) of the web page.\n",
    "\n",
    "We can also save it to a file and view the page locally within jupyter using \"File > Open\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "362048e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Webpage.html','w') as f:\n",
    "    f.write(page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bf83e8",
   "metadata": {},
   "source": [
    "The preview looks similar to the original page, but none of the links work.\n",
    "![Webpage screenshot](https://i.imgur.com/Eg67q97.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fae3f5",
   "metadata": {},
   "source": [
    "## Parse the HTML source code using beautiful soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798e0b58",
   "metadata": {},
   "source": [
    "To extract information from the HTML source code of a webpage programmatically, we can use the [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea2b538",
   "metadata": {},
   "source": [
    "Next, let's read the contents of [page](https://coinmarketcap.com/historical/) and create a `BeautifulSoup` object to parse the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b13770c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# html.parser used to parse HTML files\n",
    "doc = BeautifulSoup(page_content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de0b2fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f00475d",
   "metadata": {},
   "source": [
    "The `doc` object contains several properties and methods for extracting information from the HTML document. Let's look at a few examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc7efbf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check Cryptocurrency Price History For The Top Coins | CoinMarketCap'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the title of page\n",
    "doc.find('title').text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37227bca",
   "metadata": {},
   "source": [
    "We can use `.text` to get the text of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a1f170e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"cmc-link\" href=\"/\">22,157</a>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.find('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc7ed3c",
   "metadata": {},
   "source": [
    "That's how we extract information using Beautiful soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1069d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url):\n",
    "    \"\"\"Download a web page and return a beautiful soup doc\"\"\"\n",
    "    # Download the page\n",
    "    response = requests.get(url)\n",
    "   \n",
    "    # Ensure that the reponse is valid\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Unable to download page {}'.format(url))\n",
    "    \n",
    "    # Get the page HTML\n",
    "    page_content = response.text\n",
    "    \n",
    "    # Construct a beautiful soup document\n",
    "    doc = BeautifulSoup(page_content,'html.parser')\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef25c180",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = get_page(page_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2461432c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Check Cryptocurrency Price History For The Top Coins | CoinMarketCap</title>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.find('title')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb13eaf",
   "metadata": {},
   "source": [
    "We can now use the function `get_page` to download any web page and parse it using beautiful soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f408ecb",
   "metadata": {},
   "source": [
    "## Extract information from page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533571b2",
   "metadata": {},
   "source": [
    "![Html year tag screenshot](https://i.imgur.com/npWKDZl.png)\n",
    "\n",
    "Now, here my approach is that, extract all required information into lists from a year and then passed that into a function which contains all year information, and then convert that data into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b71d9283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(year_value):\n",
    "    date_in_year = []\n",
    "    # 'a' tag contains all dates in a month\n",
    "    weekend_days = year_value.find_all('a',{'class':'historical-link cmc-link'})\n",
    "    # Getting all dates in a year\n",
    "    for date in weekend_days:\n",
    "        date_in_year.append(date.text)\n",
    "    # return to a list\n",
    "    return date_in_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2093dc",
   "metadata": {},
   "source": [
    "We can now use `get_dates` function to get dates in a  year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75d6c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(year_value):\n",
    "    base_url = 'https://coinmarketcap.com'\n",
    "    urls = []\n",
    "    # Getting HREF link from 'a' tag \n",
    "    weekend_days = year_value.find_all('a',{'class':'historical-link cmc-link'})\n",
    "    # Getting all HREF link in a year\n",
    "    for url in weekend_days:\n",
    "        urls.append(base_url + url['href'])\n",
    "    # Saving to the list\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8b5306",
   "metadata": {},
   "source": [
    "Now, We can use `get_urls` function to get HREF link in a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27c33d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year(year_value):\n",
    "    year_list = []\n",
    "    # Getting Number of dates in a year\n",
    "    weekend_days = year_value.find_all('a',{'class':'historical-link cmc-link'})\n",
    "    # Getting year name as multiple time as Number of dates we have in that year \n",
    "    for day in weekend_days:\n",
    "        year = year_value.find('div', class_ = 'sc-c66fb3e4-1 fDOEKz').text\n",
    "        year_list.append(year)\n",
    "    return year_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd86d2c6",
   "metadata": {},
   "source": [
    "Here, we can use `get_year` function to get multiple times 'name of same year' in a list to match the length of dates and HREf link in that year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ad71a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_months(year_value):\n",
    "    month_list = []\n",
    "    \"\"\"Getting multiple times 'Months name' in that year in list that match the length of list of \n",
    "    HREF link list in that month \"\"\"\n",
    "    # Getting all months in a year \n",
    "    months = year_value.find_all('div', class_ = 'sc-9577e50d-0 cFMeUv')\n",
    "    for month in months:\n",
    "        # Getting Number of HREF tag in that month\n",
    "        Days_in_a_month = month.find_all('a', class_ = 'historical-link cmc-link')\n",
    "        for day in Days_in_a_month:\n",
    "            # Appending month name in a list as no. of HREF tags in that month\n",
    "            month_name = month.find('div', class_ = 'sc-9577e50d-1 jEphuI')\n",
    "            month_list.append(month_name.text)\n",
    "    return month_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d32550",
   "metadata": {},
   "source": [
    "We can use `get_months` function to get Months name multiple times in a list thats length equal to HREF link list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8d2c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data(doc):\n",
    "    # Getting All years from the beautifulsoup \n",
    "    years = doc.find_all('div', {'class':'sc-c66fb3e4-0 ixMSjS'})\n",
    "    # Define dictionary\n",
    "    data_dict = {'Year':[], 'Month':[], 'Week Days Number':[], 'Website': []}\n",
    "    # Storing all year data into dictionary\n",
    "    for year in years:\n",
    "        data_dict['Year'] += get_year(year)\n",
    "        data_dict['Month'] += get_months(year)\n",
    "        data_dict['Week Days Number'] += get_dates(year)\n",
    "        data_dict['Website'] += get_urls(year)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367e5cc2",
   "metadata": {},
   "source": [
    "Finally, We got complete page data  with the help of `get_all_data` function.\n",
    "\n",
    "Now converting this Dictionary into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "382dcaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(doc):\n",
    "    data_dict = get_all_data(doc)\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5b349f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week Days Number</th>\n",
       "      <th>Website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>April</td>\n",
       "      <td>28</td>\n",
       "      <td>https://coinmarketcap.com/historical/20130428/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>May</td>\n",
       "      <td>5</td>\n",
       "      <td>https://coinmarketcap.com/historical/20130505/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>May</td>\n",
       "      <td>12</td>\n",
       "      <td>https://coinmarketcap.com/historical/20130512/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>May</td>\n",
       "      <td>19</td>\n",
       "      <td>https://coinmarketcap.com/historical/20130519/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>May</td>\n",
       "      <td>26</td>\n",
       "      <td>https://coinmarketcap.com/historical/20130526/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>June</td>\n",
       "      <td>2</td>\n",
       "      <td>https://coinmarketcap.com/historical/20130602/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>June</td>\n",
       "      <td>9</td>\n",
       "      <td>https://coinmarketcap.com/historical/20130609/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013</td>\n",
       "      <td>June</td>\n",
       "      <td>16</td>\n",
       "      <td>https://coinmarketcap.com/historical/20130616/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013</td>\n",
       "      <td>June</td>\n",
       "      <td>23</td>\n",
       "      <td>https://coinmarketcap.com/historical/20130623/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013</td>\n",
       "      <td>June</td>\n",
       "      <td>30</td>\n",
       "      <td>https://coinmarketcap.com/historical/20130630/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month Week Days Number  \\\n",
       "0  2013  April               28   \n",
       "1  2013    May                5   \n",
       "2  2013    May               12   \n",
       "3  2013    May               19   \n",
       "4  2013    May               26   \n",
       "5  2013   June                2   \n",
       "6  2013   June                9   \n",
       "7  2013   June               16   \n",
       "8  2013   June               23   \n",
       "9  2013   June               30   \n",
       "\n",
       "                                          Website  \n",
       "0  https://coinmarketcap.com/historical/20130428/  \n",
       "1  https://coinmarketcap.com/historical/20130505/  \n",
       "2  https://coinmarketcap.com/historical/20130512/  \n",
       "3  https://coinmarketcap.com/historical/20130519/  \n",
       "4  https://coinmarketcap.com/historical/20130526/  \n",
       "5  https://coinmarketcap.com/historical/20130602/  \n",
       "6  https://coinmarketcap.com/historical/20130609/  \n",
       "7  https://coinmarketcap.com/historical/20130616/  \n",
       "8  https://coinmarketcap.com/historical/20130623/  \n",
       "9  https://coinmarketcap.com/historical/20130630/  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_df(doc)\n",
    "df.head(10) # First 10 rows of our dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4d8fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can save this dataframe into a csv and check this file into jupyter \"File > Open\"\n",
    "df.to_csv('Week Days Number.csv',index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa5f587",
   "metadata": {},
   "source": [
    "## Get desire link from dataframe\n",
    "\n",
    "Now, creating some functions through which i can search the desire link of data by providing input as date,month and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eff1b5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving two arguments one if dataframe, and second one is Year(for which we search data in dataframe)\n",
    "def search_month_data(df,Year):\n",
    "    # Giving condition that input year should be in df\n",
    "    Week_data_yearly = df[df['Year'] == Year]\n",
    "    print(\"\"\"Enter Month Name Down:- (Hint:-) Type just correct spell, Don't worry about upper or lowercase!\"\"\")\n",
    "    Month  = input().capitalize() # '.capitalize()' will convert all months name to Capitalization order \n",
    "    # Creating Condition if month is not in given year then using input() for month again\n",
    "    while not Month in Week_data_yearly['Month'].values:\n",
    "        print(\"{} month is not in out record\".format(Month))\n",
    "        Month  = input().capitalize()\n",
    "    week_data_monthly = Week_data_yearly[Week_data_yearly['Month'] == Month]\n",
    "    print('Yes, we have data for {} month'.format(Month))\n",
    "    return week_data_monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a83bfb4",
   "metadata": {},
   "source": [
    "We can check month using `search_month_data` function in a given yearm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8292fddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used dataFrame as input\n",
    "def search_date_data(df):\n",
    "    print('Enter Year here:-')\n",
    "    Year = input()\n",
    "    # Checking year in df\n",
    "    while not Year in df.values:\n",
    "        print('{} year is not in our record'.format(Year))\n",
    "        Year = input()\n",
    "    print('Yes, We have data for {}'.format(Year))\n",
    "    # Calling `search_month_data` function that check the month in year\n",
    "    month_data = search_month_data(df,Year)\n",
    "    return month_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ac105d",
   "metadata": {},
   "source": [
    "Here, `search_date_data` function take input as 'year' and 'month', then return dates in the given month and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3acda26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_url(df):\n",
    "    month_data = search_date_data(df)\n",
    "    print(\"Enter date here from selected month!\")\n",
    "    avail_dates = list(month_data['Week Days Number'].values)\n",
    "    print(\"These are the available dates in desire months\",avail_dates)\n",
    "    date = input()\n",
    "    while not date in month_data.values:\n",
    "        print('{} date is not in our record'.format(date))\n",
    "        date = input()\n",
    "    print(\"Yes, We have records for {} date:- \".format(date))\n",
    "    # Getting the Website like\n",
    "    link = month_data[month_data['Week Days Number'] == date]['Website']\n",
    "    desire_url = link.to_string(index = False) #convert pandas series to string\n",
    "    return desire_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee35b2b",
   "metadata": {},
   "source": [
    "Now, `get_date_url` function return the HREF attribute link on the basis of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0bc19b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Year here:-\n",
      "2022\n",
      "Yes, We have data for 2022\n",
      "Enter Month Name Down:- (Hint:-) Type just correct spell, Don't worry about upper or lowercase!\n",
      "december\n",
      "Yes, we have data for December month\n",
      "Enter date here from selected month!\n",
      "These are the available dates in desire months ['4', '11', '18', '25']\n",
      "25\n",
      "Yes, We have records for 25 date:- \n"
     ]
    }
   ],
   "source": [
    "desire_url = get_date_url(df)\n",
    "#desire_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16c1a50",
   "metadata": {},
   "source": [
    "Till yet, We have completed first part of this project. So, move further and scrape second page using selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7598440f",
   "metadata": {},
   "source": [
    "## Create and load url into driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c393746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_driver(desire_url):\n",
    "    \"\"\"Creating driver\"\"\"\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    prefs = {\"profile.default_content_setting_values.notifications\" : 2}\n",
    "    chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "    chrome_options.add_argument(\"start-maximized\")\n",
    "    driver = webdriver.Chrome(options=chrome_options, service=Service(ChromeDriverManager().install()))\n",
    "    driver.get(desire_url)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c39c61",
   "metadata": {},
   "source": [
    "## Scroll web page and get tags\n",
    "Here, I'm using [execute_async_script](https://www.geeksforgeeks.org/execute_async_script-driver-method-selenium-python/#:~:text=This%20article%20revolves%20around%20execute_async_script,to%20playing%20with%20live%20code.) that are used for rendering the webpage rapidly and Executes JavaScript in the current window/frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fba6b2",
   "metadata": {},
   "source": [
    "Use the `.get()` method of the driver to load a website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "637fc7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tr_tags(driver):\n",
    "    time.sleep(1)\n",
    "     # Close the cookies if exists\n",
    "    try:\n",
    "        cookies = driver.find_element(By.CLASS_NAME,'cmc-cookie-policy-banner__close').click()\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(2)\n",
    "    # Scrolling the page slowly that all 'tr_tags' load \n",
    "    driver.execute_async_script(\n",
    "            \"\"\"\n",
    "        count = 700;\n",
    "        let callback = arguments[arguments.length - 1];\n",
    "        t = setTimeout(function scrolldown(){\n",
    "            console.log(count, t);\n",
    "            window.scrollTo(0, count);\n",
    "            if(count < (document.body.scrollHeight || document.documentElement.scrollHeight)){\n",
    "              count+= 700;\n",
    "              t = setTimeout(scrolldown, 900);\n",
    "            }else{\n",
    "              callback((document.body.scrollHeight || document.documentElement.scrollHeight));\n",
    "            }\n",
    "        }, 900);\"\"\"\n",
    "        )\n",
    "    # Getting all tr_tags\n",
    "    tr_tags = driver.find_elements(By.CLASS_NAME,'cmc-table-row')\n",
    "    return tr_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1914f0",
   "metadata": {},
   "source": [
    "Here, we successfuly get all tr_tags from desire link page using `get_tr_tags` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09faad7",
   "metadata": {},
   "source": [
    "![tr_tags](https://i.imgur.com/QjXhTx0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "deb89395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.58M/6.58M [00:01<00:00, 6.90MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"1ac162589a553f965718013c7a7aebdf\", element=\"a07d0ab2-7c3d-4081-bad7-3b25ffdf7151\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1ac162589a553f965718013c7a7aebdf\", element=\"5de211ff-cf81-42e4-9919-341ff343fb48\")>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = get_driver(desire_url)\n",
    "tr_tags = get_tr_tags(driver)\n",
    "tr_tags[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12d3e4",
   "metadata": {},
   "source": [
    "## Extract Information from tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eabf3283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_crypto(row):\n",
    "    # crypto Rank\n",
    "    crypto_rank = row.find_element(By.CLASS_NAME,'cmc-table__cell--sort-by__rank').text\n",
    "    # crypto Name\n",
    "    crypto_name = row.find_element(By.CLASS_NAME,'cmc-table__cell--sort-by__name').text\n",
    "    # Crypto Symbol\n",
    "    crypto_symbol = row.find_element(By.CLASS_NAME,'cmc-table__cell--sort-by__symbol').text\n",
    "    # Crypto marketcap and '.replace()' removes all coma's from the element \n",
    "    crypto_marketcap = row.find_element(By.CLASS_NAME,'cmc-table__cell--sort-by__market-cap').text.replace(',','')\n",
    "    # crypto price\n",
    "    crypto_price = row.find_element(By.CLASS_NAME,'cmc-table__cell--sort-by__price').text.replace(',','')\n",
    "    # crypto circulating supply\n",
    "    circulating_supply = row.find_element(By.CLASS_NAME,'cmc-table__cell--sort-by__circulating-supply').text.replace(',','')\n",
    "    # One hour change in percentage\n",
    "    change_1h = row.find_element(By.CLASS_NAME,'cmc-table__cell--sort-by__percent-change-1-h').text\n",
    "    # Twenty four hour change in percentage\n",
    "    change_24h = row.find_element(By.CLASS_NAME,'cmc-table__cell--sort-by__percent-change-24-h').text\n",
    "    # One week change i.e. 7d\n",
    "    change_7d = row.find_element(By.CLASS_NAME,'cmc-table__cell--sort-by__percent-change-7-d').text\n",
    "    # Volume 24 hour\n",
    "    volume_24h = None\n",
    "    try:\n",
    "        volume_24h = row.find_element(By.CLASS_NAME,'cmc-table__cell--sort-by__volume-24-h').text.replace(',','')\n",
    "    except:\n",
    "        pass\n",
    "    return {\n",
    "            'Rank':crypto_rank,    'Name':crypto_name, \n",
    "            'Symbol':crypto_symbol,'market Cap':crypto_marketcap, \n",
    "            'Price':crypto_price,   'Circulating Price':circulating_supply, \n",
    "            '1hour %':change_1h,    '24 Hour %':change_24h,\n",
    "            '7d %':change_7d,       'Volume(24 H)':volume_24h\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0bb468",
   "metadata": {},
   "source": [
    "Here we got all the data from first tr tag using `parse_crypto` function. Now we can parse all tr_tags and return that data into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ab9a077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Rank': '1',\n",
       " 'Name': 'Bitcoin',\n",
       " 'Symbol': 'BTC',\n",
       " 'market Cap': '$324093186300.92',\n",
       " 'Price': '$16841.99',\n",
       " 'Circulating Price': '19243168 BTC',\n",
       " '1hour %': '0.08%',\n",
       " '24 Hour %': '-0.03%',\n",
       " '7d %': '0.50%',\n",
       " 'Volume(24 H)': '$11656379938.06'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_crypto(tr_tags[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc967fd",
   "metadata": {},
   "source": [
    "We can use a list comprehension to parse all the `tr` tags in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20d8f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cryptos = [parse_crypto(tag) for tag in tr_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e24921d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cryptos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cd2b466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Rank': '1',\n",
       "  'Name': 'Bitcoin',\n",
       "  'Symbol': 'BTC',\n",
       "  'market Cap': '$324093186300.92',\n",
       "  'Price': '$16841.99',\n",
       "  'Circulating Price': '19243168 BTC',\n",
       "  '1hour %': '0.08%',\n",
       "  '24 Hour %': '-0.03%',\n",
       "  '7d %': '0.50%',\n",
       "  'Volume(24 H)': '$11656379938.06'},\n",
       " {'Rank': '2',\n",
       "  'Name': 'Ethereum',\n",
       "  'Symbol': 'ETH',\n",
       "  'market Cap': '$149169092950.40',\n",
       "  'Price': '$1218.96',\n",
       "  'Circulating Price': '122373866 ETH *',\n",
       "  '1hour %': '0.12%',\n",
       "  '24 Hour %': '-0.18%',\n",
       "  '7d %': '2.89%',\n",
       "  'Volume(24 H)': '$3942720070.47'},\n",
       " {'Rank': '3',\n",
       "  'Name': 'Tether',\n",
       "  'Symbol': 'USDT',\n",
       "  'market Cap': '$66243849258.58',\n",
       "  'Price': '$0.9999',\n",
       "  'Circulating Price': '66247647090 USDT *',\n",
       "  '1hour %': '0.00%',\n",
       "  '24 Hour %': '0.00%',\n",
       "  '7d %': '-0.02%',\n",
       "  'Volume(24 H)': '$14856104217.46'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cryptos[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b81c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_cryptos(row):\n",
    "    #list comprehension to parse all the tr tags\n",
    "    cryptos = [parse_crypto(tag) for tag in row]\n",
    "    return cryptos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020b5d29",
   "metadata": {},
   "source": [
    "We can use `get_all_cryptos` function parse all tr_tags u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499975dd",
   "metadata": {},
   "source": [
    "## Convert dictionary to dataframe and csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fde34d",
   "metadata": {},
   "source": [
    "Now, i'm again using `pandas` library again to convert dictionary into dataframe then converting this dataframe into csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31064d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(data,path):\n",
    "    # Creating pandas dataframe \n",
    "    df = pd.DataFrame(data)\n",
    "    # Convert the dataframe  into csv\n",
    "    csv  = df.to_csv(path,index = None)\n",
    "    return csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10072bc7",
   "metadata": {},
   "source": [
    "We can verify it by checking csv file in our File option"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56a1a1c",
   "metadata": {},
   "source": [
    "## Combining all function into a single function\n",
    "This function can run all the functions and create a csv of the given input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f7de6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Year here:-\n",
      "2022\n",
      "Yes, We have data for 2022\n",
      "Enter Month Name Down:- (Hint:-) Type just correct spell, Don't worry about upper or lowercase!\n",
      "december\n",
      "Yes, we have data for December month\n",
      "Enter date here from selected month!\n",
      "These are the available dates in desire months ['4', '11', '18', '25']\n",
      "25\n",
      "Yes, We have records for 25 date:- \n",
      "Found 200 rows,Parsing all rows now\n"
     ]
    }
   ],
   "source": [
    "page_url = 'https://coinmarketcap.com/historical/'\n",
    "def main_function(page_url):\n",
    "    doc = get_page(page_url)\n",
    "    df = get_df(doc)\n",
    "    desire_url = get_date_url(df)\n",
    "    driver = get_driver(desire_url)\n",
    "    tr_rows = get_tr_tags(driver)\n",
    "    print(f'Found {len(tr_rows)} rows,Parsing all rows now')\n",
    "    crypto_dict = get_all_cryptos(tr_rows)\n",
    "    csv_file = write_csv(crypto_dict,'historical data.csv')\n",
    "    return csv_file\n",
    "main_function(page_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d7717c",
   "metadata": {},
   "source": [
    "Now that we have a CSV file, we can use the `pandas` library to view its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee6ab54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>market Cap</th>\n",
       "      <th>Price</th>\n",
       "      <th>Circulating Price</th>\n",
       "      <th>1hour %</th>\n",
       "      <th>24 Hour %</th>\n",
       "      <th>7d %</th>\n",
       "      <th>Volume(24 H)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>$324093186300.92</td>\n",
       "      <td>$16841.99</td>\n",
       "      <td>19243168 BTC</td>\n",
       "      <td>0.08%</td>\n",
       "      <td>-0.03%</td>\n",
       "      <td>0.50%</td>\n",
       "      <td>$11656379938.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>$149169092950.40</td>\n",
       "      <td>$1218.96</td>\n",
       "      <td>122373866 ETH *</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>-0.18%</td>\n",
       "      <td>2.89%</td>\n",
       "      <td>$3942720070.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tether</td>\n",
       "      <td>USDT</td>\n",
       "      <td>$66243849258.58</td>\n",
       "      <td>$0.9999</td>\n",
       "      <td>66247647090 USDT *</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>-0.02%</td>\n",
       "      <td>$14856104217.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>USD Coin</td>\n",
       "      <td>USDC</td>\n",
       "      <td>$44348890607.38</td>\n",
       "      <td>$1.00</td>\n",
       "      <td>44345240440 USDC *</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.03%</td>\n",
       "      <td>$1380163674.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>BNB</td>\n",
       "      <td>BNB</td>\n",
       "      <td>$38894316962.85</td>\n",
       "      <td>$243.14</td>\n",
       "      <td>159965769 BNB *</td>\n",
       "      <td>0.06%</td>\n",
       "      <td>-0.61%</td>\n",
       "      <td>-3.19%</td>\n",
       "      <td>$298063868.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196</td>\n",
       "      <td>Ontology Gas</td>\n",
       "      <td>ONG</td>\n",
       "      <td>$77138496.55</td>\n",
       "      <td>$0.2353</td>\n",
       "      <td>327807147 ONG *</td>\n",
       "      <td>0.90%</td>\n",
       "      <td>-0.19%</td>\n",
       "      <td>1.99%</td>\n",
       "      <td>$6849565.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197</td>\n",
       "      <td>Illuvium</td>\n",
       "      <td>ILV</td>\n",
       "      <td>$76752342.88</td>\n",
       "      <td>$39.75</td>\n",
       "      <td>1930890 ILV *</td>\n",
       "      <td>0.17%</td>\n",
       "      <td>-0.82%</td>\n",
       "      <td>-3.48%</td>\n",
       "      <td>$3906970.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>Numeraire</td>\n",
       "      <td>NMR</td>\n",
       "      <td>$76336990.34</td>\n",
       "      <td>$12.96</td>\n",
       "      <td>5888504 NMR *</td>\n",
       "      <td>-0.76%</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>5.47%</td>\n",
       "      <td>$11331406.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>Nervos Network</td>\n",
       "      <td>CKB</td>\n",
       "      <td>$75849567.13</td>\n",
       "      <td>$0.002275</td>\n",
       "      <td>33340068750 CKB</td>\n",
       "      <td>0.03%</td>\n",
       "      <td>-0.62%</td>\n",
       "      <td>2.52%</td>\n",
       "      <td>$918776.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>renBTC</td>\n",
       "      <td>RENBTC</td>\n",
       "      <td>$74867821.65</td>\n",
       "      <td>$20914.56</td>\n",
       "      <td>3580 RENBTC *</td>\n",
       "      <td>0.08%</td>\n",
       "      <td>18.40%</td>\n",
       "      <td>23.56%</td>\n",
       "      <td>$1175871.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rank            Name  Symbol        market Cap      Price  \\\n",
       "0       1         Bitcoin     BTC  $324093186300.92  $16841.99   \n",
       "1       2        Ethereum     ETH  $149169092950.40   $1218.96   \n",
       "2       3          Tether    USDT   $66243849258.58    $0.9999   \n",
       "3       4        USD Coin    USDC   $44348890607.38      $1.00   \n",
       "4       5             BNB     BNB   $38894316962.85    $243.14   \n",
       "..    ...             ...     ...               ...        ...   \n",
       "195   196    Ontology Gas     ONG      $77138496.55    $0.2353   \n",
       "196   197        Illuvium     ILV      $76752342.88     $39.75   \n",
       "197   198       Numeraire     NMR      $76336990.34     $12.96   \n",
       "198   199  Nervos Network     CKB      $75849567.13  $0.002275   \n",
       "199   200          renBTC  RENBTC      $74867821.65  $20914.56   \n",
       "\n",
       "      Circulating Price 1hour % 24 Hour %    7d %     Volume(24 H)  \n",
       "0          19243168 BTC   0.08%    -0.03%   0.50%  $11656379938.06  \n",
       "1       122373866 ETH *   0.12%    -0.18%   2.89%   $3942720070.47  \n",
       "2    66247647090 USDT *   0.00%     0.00%  -0.02%  $14856104217.46  \n",
       "3    44345240440 USDC *   0.00%     0.00%   0.03%   $1380163674.19  \n",
       "4       159965769 BNB *   0.06%    -0.61%  -3.19%    $298063868.05  \n",
       "..                  ...     ...       ...     ...              ...  \n",
       "195     327807147 ONG *   0.90%    -0.19%   1.99%      $6849565.81  \n",
       "196       1930890 ILV *   0.17%    -0.82%  -3.48%      $3906970.39  \n",
       "197       5888504 NMR *  -0.76%     0.83%   5.47%     $11331406.91  \n",
       "198     33340068750 CKB   0.03%    -0.62%   2.52%       $918776.25  \n",
       "199       3580 RENBTC *   0.08%    18.40%  23.56%      $1175871.38  \n",
       "\n",
       "[200 rows x 10 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('historical data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff7faa1",
   "metadata": {},
   "source": [
    "### All functions in one Cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b4db183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and import libraries and packages\n",
    "!pip install requests --upgrade --quiet\n",
    "import requests\n",
    "\n",
    "!pip install beautifulsoup4 --upgrade --quiet\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "!pip install pandas --upgrade --quiet\n",
    "import pandas as pd\n",
    "\n",
    "!pip install selenium --upgrade --quiet\n",
    "# WebDriver class will connect us to a browserâ€™s instance\n",
    "from selenium import webdriver\n",
    "\n",
    "# Keys class lets us emulate the stroke of keyboard keys\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "#Object that manages the starting and stopping of the ChromeDriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "# Use with Chrome\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Set of supported locator strategies.\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# used to manipulate various properties of Chrome driver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "#import time\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32ca6e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Year here:-\n",
      "2022\n",
      "Yes, We have data for 2022\n",
      "Enter Month Name Down:- (Hint:-) Type just correct spell, Don't worry about upper or lowercase!\n",
      "december\n",
      "Yes, we have data for December month\n",
      "Enter date here from selected month!\n",
      "These are the available dates in desire months ['4', '11', '18', '25']\n",
      "25\n",
      "Yes, We have records for 25 date:- \n",
      "Found 200 rows,Parsing all rows now\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>market Cap</th>\n",
       "      <th>Price</th>\n",
       "      <th>Circulating Price</th>\n",
       "      <th>1hour %</th>\n",
       "      <th>24 Hour %</th>\n",
       "      <th>7d %</th>\n",
       "      <th>Volume(24 H)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>$324093186300.92</td>\n",
       "      <td>$16841.99</td>\n",
       "      <td>19243168 BTC</td>\n",
       "      <td>0.08%</td>\n",
       "      <td>-0.03%</td>\n",
       "      <td>0.50%</td>\n",
       "      <td>$11656379938.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>ETH</td>\n",
       "      <td>$149169092950.40</td>\n",
       "      <td>$1218.96</td>\n",
       "      <td>122373866 ETH *</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>-0.18%</td>\n",
       "      <td>2.89%</td>\n",
       "      <td>$3942720070.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tether</td>\n",
       "      <td>USDT</td>\n",
       "      <td>$66243849258.58</td>\n",
       "      <td>$0.9999</td>\n",
       "      <td>66247647090 USDT *</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>-0.02%</td>\n",
       "      <td>$14856104217.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>USD Coin</td>\n",
       "      <td>USDC</td>\n",
       "      <td>$44348890607.38</td>\n",
       "      <td>$1.00</td>\n",
       "      <td>44345240440 USDC *</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.03%</td>\n",
       "      <td>$1380163674.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>BNB</td>\n",
       "      <td>BNB</td>\n",
       "      <td>$38894316962.85</td>\n",
       "      <td>$243.14</td>\n",
       "      <td>159965769 BNB *</td>\n",
       "      <td>0.06%</td>\n",
       "      <td>-0.61%</td>\n",
       "      <td>-3.19%</td>\n",
       "      <td>$298063868.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196</td>\n",
       "      <td>Ontology Gas</td>\n",
       "      <td>ONG</td>\n",
       "      <td>$77138496.55</td>\n",
       "      <td>$0.2353</td>\n",
       "      <td>327807147 ONG *</td>\n",
       "      <td>0.90%</td>\n",
       "      <td>-0.19%</td>\n",
       "      <td>1.99%</td>\n",
       "      <td>$6849565.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197</td>\n",
       "      <td>Illuvium</td>\n",
       "      <td>ILV</td>\n",
       "      <td>$76752342.88</td>\n",
       "      <td>$39.75</td>\n",
       "      <td>1930890 ILV *</td>\n",
       "      <td>0.17%</td>\n",
       "      <td>-0.82%</td>\n",
       "      <td>-3.48%</td>\n",
       "      <td>$3906970.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>Numeraire</td>\n",
       "      <td>NMR</td>\n",
       "      <td>$76336990.34</td>\n",
       "      <td>$12.96</td>\n",
       "      <td>5888504 NMR *</td>\n",
       "      <td>-0.76%</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>5.47%</td>\n",
       "      <td>$11331406.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>Nervos Network</td>\n",
       "      <td>CKB</td>\n",
       "      <td>$75849567.13</td>\n",
       "      <td>$0.002275</td>\n",
       "      <td>33340068750 CKB</td>\n",
       "      <td>0.03%</td>\n",
       "      <td>-0.62%</td>\n",
       "      <td>2.52%</td>\n",
       "      <td>$918776.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>renBTC</td>\n",
       "      <td>RENBTC</td>\n",
       "      <td>$74867821.65</td>\n",
       "      <td>$20914.56</td>\n",
       "      <td>3580 RENBTC *</td>\n",
       "      <td>0.08%</td>\n",
       "      <td>18.40%</td>\n",
       "      <td>23.56%</td>\n",
       "      <td>$1175871.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rank            Name  Symbol        market Cap      Price  \\\n",
       "0       1         Bitcoin     BTC  $324093186300.92  $16841.99   \n",
       "1       2        Ethereum     ETH  $149169092950.40   $1218.96   \n",
       "2       3          Tether    USDT   $66243849258.58    $0.9999   \n",
       "3       4        USD Coin    USDC   $44348890607.38      $1.00   \n",
       "4       5             BNB     BNB   $38894316962.85    $243.14   \n",
       "..    ...             ...     ...               ...        ...   \n",
       "195   196    Ontology Gas     ONG      $77138496.55    $0.2353   \n",
       "196   197        Illuvium     ILV      $76752342.88     $39.75   \n",
       "197   198       Numeraire     NMR      $76336990.34     $12.96   \n",
       "198   199  Nervos Network     CKB      $75849567.13  $0.002275   \n",
       "199   200          renBTC  RENBTC      $74867821.65  $20914.56   \n",
       "\n",
       "      Circulating Price 1hour % 24 Hour %    7d %     Volume(24 H)  \n",
       "0          19243168 BTC   0.08%    -0.03%   0.50%  $11656379938.06  \n",
       "1       122373866 ETH *   0.12%    -0.18%   2.89%   $3942720070.47  \n",
       "2    66247647090 USDT *   0.00%     0.00%  -0.02%  $14856104217.46  \n",
       "3    44345240440 USDC *   0.00%     0.00%   0.03%   $1380163674.19  \n",
       "4       159965769 BNB *   0.06%    -0.61%  -3.19%    $298063868.05  \n",
       "..                  ...     ...       ...     ...              ...  \n",
       "195     327807147 ONG *   0.90%    -0.19%   1.99%      $6849565.81  \n",
       "196       1930890 ILV *   0.17%    -0.82%  -3.48%      $3906970.39  \n",
       "197       5888504 NMR *  -0.76%     0.83%   5.47%     $11331406.91  \n",
       "198     33340068750 CKB   0.03%    -0.62%   2.52%       $918776.25  \n",
       "199       3580 RENBTC *   0.08%    18.40%  23.56%      $1175871.38  \n",
       "\n",
       "[200 rows x 10 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_url = 'https://coinmarketcap.com/historical/'\n",
    "# main_function will execute all required function and returns csv file of extracted data\n",
    "def main_function(page_url):\n",
    "    doc = get_page(page_url)\n",
    "    df = get_df(doc)\n",
    "    desire_url = get_date_url(df)\n",
    "    driver = get_driver(desire_url)\n",
    "    tr_rows = get_tr_tags(driver)\n",
    "    print(f'Found {len(tr_rows)} rows,Parsing all rows now')\n",
    "    crypto_dict = get_all_cryptos(tr_rows)\n",
    "    csv_file = write_csv(crypto_dict,'historical_data.csv')\n",
    "    csv = pd.read_csv('historical_data.csv')\n",
    "    return csv\n",
    "   \n",
    "def get_page(url):\n",
    "    \"\"\"Download a web page and return a beautiful soup doc\"\"\"\n",
    "    # Download the page\n",
    "    response = requests.get(url)\n",
    "   \n",
    "    # Ensure that the reponse is valid\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Unable to download page {}'.format(url))\n",
    "    \n",
    "    # Get the page HTML\n",
    "    page_content = response.text\n",
    "    \n",
    "    # Construct a beautiful soup document\n",
    "    doc = BeautifulSoup(page_content,'html.parser')\n",
    "    return doc\n",
    "\n",
    "def get_dates(year_value):\n",
    "    date_in_year = []\n",
    "    # 'a' tag contains all dates in a month\n",
    "    weekend_days = year_value.find_all('a',{'class':'historical-link cmc-link'})\n",
    "    # Getting all dates in a year\n",
    "    for date in weekend_days:\n",
    "        date_in_year.append(date.text)\n",
    "    # return to a list\n",
    "    return date_in_year\n",
    "\n",
    "def get_urls(year_value):\n",
    "    base_url = 'https://coinmarketcap.com'\n",
    "    urls = []\n",
    "    # Getting HREF link from 'a' tag \n",
    "    weekend_days = year_value.find_all('a',{'class':'historical-link cmc-link'})\n",
    "    # Getting all HREF link in a year\n",
    "    for url in weekend_days:\n",
    "        urls.append(base_url + url['href'])\n",
    "    # Saving to the list\n",
    "    return urls\n",
    "\n",
    "def get_year(year_value):\n",
    "    year_list = []\n",
    "    # Getting Number of dates in a year\n",
    "    weekend_days = year_value.find_all('a',{'class':'historical-link cmc-link'})\n",
    "    # Getting year name as multiple time as Number of dates we have in that year \n",
    "    for day in weekend_days:\n",
    "        year = year_value.find('div', class_ = 'sc-c66fb3e4-1 fDOEKz').text\n",
    "        year_list.append(year)\n",
    "    return year_list\n",
    "\n",
    "def get_months(year_value):\n",
    "    month_list = []\n",
    "    \"\"\"Getting multiple times 'Months name' in that year in list that match the length of list of \n",
    "    HREF link list in that month \"\"\"\n",
    "    # Getting all months in a year \n",
    "    months = year_value.find_all('div', class_ = 'sc-9577e50d-0 cFMeUv')\n",
    "    for month in months:\n",
    "        # Getting Number of HREF tag in that month\n",
    "        Days_in_a_month = month.find_all('a', class_ = 'historical-link cmc-link')\n",
    "        for day in Days_in_a_month:\n",
    "            # Appending month name in a list as no. of HREF tags in that month\n",
    "            month_name = month.find('div', class_ = 'sc-9577e50d-1 jEphuI')\n",
    "            month_list.append(month_name.text)\n",
    "    return month_list\n",
    "\n",
    "def get_all_data(doc):\n",
    "    # Getting All years from the beautifulsoup \n",
    "    years = doc.find_all('div', {'class':'sc-c66fb3e4-0 ixMSjS'})\n",
    "    # Define dictionary\n",
    "    data_dict = {'Year':[], 'Month':[], 'Week Days Number':[], 'Website': []}\n",
    "    # Storing all year data into dictionary\n",
    "    for year in years:\n",
    "        data_dict['Year'] += get_year(year)\n",
    "        data_dict['Month'] += get_months(year)\n",
    "        data_dict['Week Days Number'] += get_dates(year)\n",
    "        data_dict['Website'] += get_urls(year)\n",
    "    return data_dict\n",
    "\n",
    "def get_df(doc):\n",
    "    data_dict = get_all_data(doc)\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    return df\n",
    "\n",
    "# Giving two arguments one if dataframe, and second one is Year(for which we search data in dataframe)\n",
    "def search_month_data(df,Year):\n",
    "    # Giving condition that input year should be in df\n",
    "    Week_data_yearly = df[df['Year'] == Year]\n",
    "    print(\"\"\"Enter Month Name Down:- (Hint:-) Type just correct spell, Don't worry about upper or lowercase!\"\"\")\n",
    "    Month  = input().capitalize() # '.capitalize()' will convert all months name to Capitalization order \n",
    "    # Creating Condition if month is not in given year then using input() for month again\n",
    "    while not Month in Week_data_yearly['Month'].values:\n",
    "        print(\"{} month is not in out record\".format(Month))\n",
    "        Month  = input().capitalize()\n",
    "    week_data_monthly = Week_data_yearly[Week_data_yearly['Month'] == Month]\n",
    "    print('Yes, we have data for {} month'.format(Month))\n",
    "    return week_data_monthly\n",
    "\n",
    "# Used dataFrame as input\n",
    "def search_date_data(df):\n",
    "    print('Enter Year here:-')\n",
    "    Year = input()\n",
    "    # Checking year in df\n",
    "    while not Year in df.values:\n",
    "        print('{} year is not in our record'.format(Year))\n",
    "        Year = input()\n",
    "    print('Yes, We have data for {}'.format(Year))\n",
    "    # Calling `search_month_data` function that check the month in year\n",
    "    month_data = search_month_data(df,Year)\n",
    "    return month_data\n",
    "\n",
    "def get_date_url(df):\n",
    "    month_data = search_date_data(df)\n",
    "    print(\"Enter date here from selected month!\")\n",
    "    avail_dates = list(month_data['Week Days Number'].values)\n",
    "    print(\"These are the available dates in desire months\",avail_dates)\n",
    "    date = input()\n",
    "    while not date in month_data.values:\n",
    "        print('{} date is not in our record'.format(date))\n",
    "        date = input()\n",
    "    print(\"Yes, We have records for {} date:- \".format(date))\n",
    "    # Getting the Website like\n",
    "    link = month_data[month_data['Week Days Number'] == date]['Website']\n",
    "    desire_url = link.to_string(index = False) #convert pandas series to string\n",
    "    return desire_url\n",
    "\n",
    "def get_driver(desire_url):\n",
    "    \"\"\"Creating driver\"\"\"\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    prefs = {\"profile.default_content_setting_values.notifications\" : 2}\n",
    "    chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "    chrome_options.add_argument(\"start-maximized\")\n",
    "    driver = webdriver.Chrome(options=chrome_options, service=Service(ChromeDriverManager().install()))\n",
    "    driver.get(desire_url)\n",
    "    return driver\n",
    "\n",
    "def get_tr_tags(driver):\n",
    "    time.sleep(1)\n",
    "     # Close the cookies if exists\n",
    "    try:\n",
    "        cookies = driver.find_element(By.CLASS_NAME,'cmc-cookie-policy-banner__close').click()\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(2)\n",
    "    # Scrolling the page slowly that all 'tr_tags' load \n",
    "    driver.execute_async_script(\n",
    "            \"\"\"\n",
    "        count = 700;\n",
    "        let callback = arguments[arguments.length - 1];\n",
    "        t = setTimeout(function scrolldown(){\n",
    "            console.log(count, t);\n",
    "            window.scrollTo(0, count);\n",
    "            if(count < (document.body.scrollHeight || document.documentElement.scrollHeight)){\n",
    "              count+= 700;\n",
    "              t = setTimeout(scrolldown, 900);\n",
    "            }else{\n",
    "              callback((document.body.scrollHeight || document.documentElement.scrollHeight));\n",
    "            }\n",
    "        }, 900);\"\"\"\n",
    "        )\n",
    "    # Getting all tr_tags\n",
    "    tr_tags = driver.find_elements(By.CLASS_NAME,'cmc-table-row')\n",
    "    return tr_tags\n",
    "\n",
    "def parse_crypto(row):\n",
    "    # crypto Rank\n",
    "    crypto_rank = row.find_element(By.CLASS_NAME,'cmc-table__cell--sort-by__rank').text\n",
    "    # crypto Name\n",
    "    crypto_name = row.find_element(By.CLASS_NAME,'cmc-table__cell--sort-by__name').text\n",
    "    # Crypto Symbol\n",
    "    crypto_symbol = row.find_element(By.CLASS_NAME,'cmc-table__cell--sort-by__symbol').text\n",
    "    # Crypto marketcap and '.replace()' removes all coma's from the element \n",
    "    crypto_marketcap = row.find_element(By.CLASS_NAME,'cmc-table__cell--sort-by__market-cap').text.replace(',','')\n",
    "    # crypto price\n",
    "    crypto_price = row.find_element(By.CLASS_NAME,'cmc-table__cell--sort-by__price').text.replace(',','')\n",
    "    # crypto circulating supply\n",
    "    circulating_supply = row.find_element(By.CLASS_NAME,'cmc-table__cell--sort-by__circulating-supply').text.replace(',','')\n",
    "    # One hour change in percentage\n",
    "    change_1h = row.find_element(By.CLASS_NAME,'cmc-table__cell--sort-by__percent-change-1-h').text\n",
    "    # Twenty four hour change in percentage\n",
    "    change_24h = row.find_element(By.CLASS_NAME,'cmc-table__cell--sort-by__percent-change-24-h').text\n",
    "    # One week change i.e. 7d\n",
    "    change_7d = row.find_element(By.CLASS_NAME,'cmc-table__cell--sort-by__percent-change-7-d').text\n",
    "    # Volume 24 hour\n",
    "    volume_24h = None\n",
    "    try:\n",
    "        volume_24h = row.find_element(By.CLASS_NAME,'cmc-table__cell--sort-by__volume-24-h').text.replace(',','')\n",
    "    except:\n",
    "        pass\n",
    "    return {\n",
    "            'Rank':crypto_rank,    'Name':crypto_name, \n",
    "            'Symbol':crypto_symbol,'market Cap':crypto_marketcap, \n",
    "            'Price':crypto_price,   'Circulating Price':circulating_supply, \n",
    "            '1hour %':change_1h,    '24 Hour %':change_24h,\n",
    "            '7d %':change_7d,       'Volume(24 H)':volume_24h\n",
    "           }\n",
    "def get_all_cryptos(row):\n",
    "    cryptos = [parse_crypto(tag) for tag in row]\n",
    "    return cryptos\n",
    "\n",
    "def write_csv(data,path):\n",
    "    # Creating pandas dataframe \n",
    "    df = pd.DataFrame(data)\n",
    "    # Convert the dataframe  into csv\n",
    "    csv  = df.to_csv(path,index = None)\n",
    "    return csv\n",
    "# Calling main function\n",
    "main_function(page_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f429fc",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "1. Download the webpage using requests\n",
    "2. Parse the HTML source code using beautiful soup\n",
    "3. Compile extracted information into python lists and dictionaries\n",
    "4. Save the extracted information to a dataframe\n",
    "5. Get the desire link using input functions for a input data(like date,moonth and year)\n",
    "6. Install and Import the required packages.\n",
    "7. Create the selenium webdriver object and Load url into driver\n",
    "8. Compile extracted information into python lists and dictionaries\n",
    "9. Save the extracted information to a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b98408",
   "metadata": {},
   "source": [
    "## Refrences:\n",
    "1. [Web Scraping and Rest APIs](https://jovian.ai/learn/zero-to-data-analyst-bootcamp/lesson/web-scraping-and-rest-apis) Introduction to Web Scraping and REST APIs By [Jovian](https://jovian.ai/)\n",
    "2. [BeautifulSoup](https://beautiful-soup-4.readthedocs.io/en/latest/) - Beautiful Soup Documentation\n",
    "3. [Workshop - Web Scraping with Selenium & AWS](https://jovian.ai/learn/zero-to-data-analyst-bootcamp/lesson/workshop-web-scraping-with-selenium-aws) Basics of Selenium and webscraping by [Jovian](https://jovian.ai/)\n",
    "\n",
    "4. [Selenium Documentation](https://selenium-python.readthedocs.io/) - Selenium With Python\n",
    "5. [Apna College](https://www.youtube.com/watch?v=HcOc7P5BMi4) - HTML Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4f84a5",
   "metadata": {},
   "source": [
    "## Future Work:\n",
    "- comparison analysis how the prices, changes in % etc. vary from one crypto to another in same day's.\n",
    "- We can make a comparison using Machine Learning techniques like is really one cryptocurrencies depends on other cryptocurrencies , if yes then whats the relation between them.\n",
    "- Forecasting Future Prices of Cryptocurrency using Historical Data.\n",
    "- Bitcoin Price Prediction Based on Other Cryptocurrencies Using Machine Learning and Time Series Analysis.\n",
    "- From this csv, we can get any crypto time series data just by few more coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b6dea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jovian\n",
    "jovian.commit(files = ['historical data.csv','Week Days Number.csv','CoinMarketCap web scrapping_project.ipynb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ac3f15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
